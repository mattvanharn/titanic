{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./titanic/lib/python3.11/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./titanic/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./titanic/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./titanic/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./titanic/lib/python3.11/site-packages (from tensorflow) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./titanic/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./titanic/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./titanic/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in ./titanic/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./titanic/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./titanic/lib/python3.11/site-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./titanic/lib/python3.11/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./titanic/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in ./titanic/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./titanic/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./titanic/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./titanic/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./titanic/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./titanic/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kaggle in ./titanic/lib/python3.11/site-packages (1.5.16)\n",
      "Requirement already satisfied: six>=1.10 in ./titanic/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in ./titanic/lib/python3.11/site-packages (from kaggle) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil in ./titanic/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in ./titanic/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./titanic/lib/python3.11/site-packages (from kaggle) (4.66.1)\n",
      "Requirement already satisfied: python-slugify in ./titanic/lib/python3.11/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in ./titanic/lib/python3.11/site-packages (from kaggle) (2.1.0)\n",
      "Requirement already satisfied: bleach in ./titanic/lib/python3.11/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in ./titanic/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in ./titanic/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./titanic/lib/python3.11/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./titanic/lib/python3.11/site-packages (from requests->kaggle) (3.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow_decision_forests in ./titanic/lib/python3.11/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (1.26.2)\n",
      "Requirement already satisfied: pandas in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.1.4)\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.15.0.post1)\n",
      "Requirement already satisfied: six in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (1.16.0)\n",
      "Requirement already satisfied: absl-py in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.0.0)\n",
      "Requirement already satisfied: wheel in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (0.42.0)\n",
      "Requirement already satisfied: wurlitzer in ./titanic/lib/python3.11/site-packages (from tensorflow_decision_forests) (3.0.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.23.4)\n",
      "Requirement already satisfied: setuptools in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (65.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in ./titanic/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./titanic/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./titanic/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./titanic/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2023.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./titanic/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./titanic/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./titanic/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./titanic/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./titanic/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./titanic/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./titanic/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 14:36:29.705990: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 14:36:29.706072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 14:36:29.708500: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 14:36:29.724484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 14:36:31.568287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TF-DF 1.8.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 14:36:33.440922: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:33.500163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:33.500396: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Set up TensorFlow\n",
    "# For GPU users\n",
    "%pip install tensorflow\n",
    "%pip install kaggle\n",
    "%pip install tensorflow_decision_forests\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow_decision_forests as tfdf\n",
    "print(f\"Found TF-DF {tfdf.__version__}\")\n",
    "\n",
    "# Verify the GPU setup\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"titanic/data/titanic.zip\"):\n",
    "  !kaggle competitions download -c titanic -p titanic/data\n",
    "  !unzip titanic/data/titanic.zip -d titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00.0 3D controller: NVIDIA Corporation GP107M [GeForce GTX 1050 Mobile] (rev a1)\n"
     ]
    }
   ],
   "source": [
    "!lspci | grep -i nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"titanic/data/train.csv\")\n",
    "serving_df = pd.read_csv(\"titanic/data/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_number</th>\n",
       "      <th>Ticket_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund Mr Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen Mr William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                              Name     Sex   Age  SibSp  \\\n",
       "0                            Braund Mr Owen Harris    male  22.0      1   \n",
       "1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n",
       "2                             Heikkinen Miss Laina  female  26.0      0   \n",
       "3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n",
       "4                           Allen Mr William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n",
       "0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n",
       "1      0          PC 17599  71.2833   C85        C         17599          PC  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n",
       "3      0            113803  53.1000  C123        S        113803        NONE  \n",
       "4      0            373450   8.0500   NaN        S        373450        NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def normalize_name(x):\n",
    "        \"\"\"\n",
    "        Normalize name\n",
    "        \"\"\"\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def ticket_number(x):\n",
    "        \"\"\"\n",
    "        Extract ticket number\n",
    "        \"\"\"\n",
    "        return x.split(\" \")[-1]\n",
    "\n",
    "    def ticket_item(x):\n",
    "        \"\"\"\n",
    "        Extract ticket item\n",
    "        \"\"\"\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "\n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_serving_df = preprocess(serving_df)\n",
    "\n",
    "preprocessed_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n"
     ]
    }
   ],
   "source": [
    "# Create list of input features\n",
    "input_features = list(preprocessed_train_df.columns)\n",
    "input_features.remove(\"Ticket\")\n",
    "input_features.remove(\"PassengerId\")\n",
    "input_features.remove(\"Survived\")\n",
    "\n",
    "print(f\"Input features: {input_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Pandas Dataset to Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 14:36:33.884604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:33.885162: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:33.885517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:34.007646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:34.008210: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:34.008777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 14:36:34.009039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1734 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "def tokenize_names(features, labels=None):\n",
    "    \"\"\"\n",
    "    Divide the names into tokens. TF-DFcan consume text tokens natively.\n",
    "    \"\"\"\n",
    "    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    preprocessed_train_df, label=\"Survived\"\n",
    ").map(tokenize_names)\n",
    "serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(\n",
    "    tokenize_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model With Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-12-30 14:36:34.6185 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-12-30 14:36:34.6192 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-12-30 14:36:34.6193 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "2023-12-30 14:36:40.783312: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:504] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-12.2\n",
      "  /usr/local/cuda\n",
      "  /home/mattvanharn/repos/kaggle/titanic/titanic/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/mattvanharn/repos/kaggle/titanic/titanic/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "[INFO 23-12-30 14:36:41.2641 EST kernel.cc:1233] Loading model from path /tmp/tmp5yiq66lc/model/ with prefix 6aebb495253f494e\n",
      "[INFO 23-12-30 14:36:41.2734 EST quick_scorer_extended.cc:903] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "[INFO 23-12-30 14:36:41.2739 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 23-12-30 14:36:41.2739 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8229166865348816 Loss: 0.8424865007400513\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose=0,  # very few logs\n",
    "    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "    exclude_non_specified_features=True,  # Only use features in \"features\"\n",
    "    random_seed=3,\n",
    ")\n",
    "model.fit(train_ds)\n",
    "\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to ~/repos/kaggle/titanic/working/submission.csv\n",
      "PassengerId,Survived\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,1\n",
      "897,0\n",
      "898,1\n",
      "899,0\n",
      "900,1\n"
     ]
    }
   ],
   "source": [
    "def prediction_to_kaggle_format(model, threshold = 0.5):\n",
    "  proba_survive = model.predict(serving_ds, verbose = 0)[:, 0]\n",
    "  return pd.DataFrame({\n",
    "      \"PassengerId\": serving_df[\"PassengerId\"],\n",
    "      \"Survived\": (proba_survive > threshold).astype(int)\n",
    "  })\n",
    "\n",
    "def make_submission(kaggle_predictions):\n",
    "  path = \"~/repos/kaggle/titanic/working/submission.csv\"\n",
    "  kaggle_predictions.to_csv(path, index = False)\n",
    "  print(f\"Submission saved to {path}\")\n",
    "\n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "make_submission(kaggle_predictions)\n",
    "!head ~/repos/kaggle/titanic/working/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model With Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp6bbennep as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-12-30 14:36:43.7020 EST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-12-30 14:36:43.7020 EST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-12-30 14:36:43.7021 EST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 23-12-30 14:38:24.0437 EST kernel.cc:1233] Loading model from path /tmp/tmp6bbennep/model/ with prefix f4e98927044f4247\n",
      "[INFO 23-12-30 14:38:24.0742 EST decision_forest.cc:660] Model loaded with 30 root(s), 2236 node(s), and 12 input feature(s).\n",
      "[INFO 23-12-30 14:38:24.0743 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 23-12-30 14:38:24.0743 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8630136847496033 Loss: 0.6749962568283081\n"
     ]
    }
   ],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=1000)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n",
    "\n",
    "global_search_space = tuner.choice(\n",
    "    \"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True\n",
    ")\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "\n",
    "# tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "oblique_space.choice(\n",
    "    \"sparse_oblique_normalization\", [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"]\n",
    ")\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n",
    "\n",
    "# Tune the model. Notice the tuner = tuner\n",
    "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "tuned_model.fit(train_ds, verbose=0)\n",
    "\n",
    "tuned_self_evaluation = tuned_model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss: {tuned_self_evaluation.loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
